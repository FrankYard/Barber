{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lpips\n",
    "from model import Generator\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgfiles = ['..\\\\woman.png']\n",
    "ckpt = '..\\\\stylegan2-ffhq-config-f.pt'\n",
    "n_mean_latent = 10**6\n",
    "\n",
    "size = 1024\n",
    "resize = min(256, size)\n",
    "\n",
    "device = \"cuda\"\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(resize),\n",
    "        transforms.CenterCrop(resize),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for imgfile in imgfiles:\n",
    "    img = transform(Image.open(imgfile).convert(\"RGB\"))\n",
    "    imgs.append(img)\n",
    "    \n",
    "imgs = torch.stack(imgs, 0).to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_ema = Generator(size, 512, 8)\n",
    "g_ema.load_state_dict(torch.load(ckpt)[\"g_ema\"], strict=False)\n",
    "g_ema.eval()\n",
    "g_ema = g_ema.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n",
      "900000\n",
      "800000\n",
      "700000\n",
      "600000\n",
      "500000\n",
      "400000\n",
      "300000\n",
      "200000\n",
      "100000\n",
      "stacking...\n"
     ]
    }
   ],
   "source": [
    "CHUNK = 10**5\n",
    "count = n_mean_latent\n",
    "torch.manual_seed(1)\n",
    "latent_out_list = []\n",
    "with torch.no_grad():\n",
    "    while count > 0:\n",
    "        print(count)\n",
    "        noise_sample = torch.randn(CHUNK, 512, device=device)\n",
    "        latent_out = g_ema.style(noise_sample)\n",
    "        latent_out_list.append(latent_out)\n",
    "        count -= CHUNK\n",
    "    print(\"stacking...\")\n",
    "    latent_out = torch.vstack(latent_out_list)\n",
    "    latent_mean = latent_out.mean(0)\n",
    "    # latent_std = ((latent_out - latent_mean).pow(2).sum() / n_mean_latent) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_out_dict = {\n",
    "    'W': latent_out,\n",
    "    'mean':latent_mean\n",
    "}\n",
    "torch.save(latent_out_dict, 'latent_back')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = F.leaky_relu(latent_out, negative_slope=5)\n",
    "P_dict = {'P': P}\n",
    "torch.save(P_dict, 'P')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load P and do SVD (for PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "P_dict = torch.load('P')\n",
    "P = P_dict['P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_mean = P.mean(0)\n",
    "_, S, V = torch.svd(P - P_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd_dict = {'S':S, 'V':V, 'mean': P_mean}\n",
    "torch.save(svd_dict, 'svd_S_V')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5374.1353, 4875.6348], device='cuda:0') tensor([5470.8291, 5015.5801], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# _, S_2, V_2 = torch.pca_lowrank(P, 2, center=True)\n",
    "# print(S_2, S[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save mean and std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dict = torch.load('latent_back')\n",
    "latent_mean = latent_dict['mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_out = latent_dict['W']\n",
    "latent_std = ((latent_out - latent_mean).pow(2).sum() / (n_mean_latent - 1) ) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_stat = {'mean': latent_mean, 'std': latent_std}\n",
    "torch.save(latent_stat, 'latent_stat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II2S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_stat = torch.load('latent_stat')\n",
    "latent_mean, latent_std = latent_stat['mean'], latent_stat['std']\n",
    "svd_dict = torch.load('svd_S_V')\n",
    "S, V, P_mean = svd_dict['S'], svd_dict['V'], svd_dict['mean']\n",
    "S_inv = 1 / S\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PN_loss(latent_in, P_mean, V, S_inv):\n",
    "    x = F.leaky_relu(latent_in, negative_slope=5)\n",
    "    v = torch.matmul(x - P_mean, V) * S_inv\n",
    "    return (v ** 2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Perceptual loss...\n",
      "Loading model from: d:\\S\\PyCharmProject\\StyleGAN2-ADA-main\\stylegan2-pytorch\\lpips\\weights\\v0.1\\vgg.pth\n",
      "...[net-lin [vgg]] initialized\n",
      "...Done\n"
     ]
    }
   ],
   "source": [
    "percept = lpips.PerceptualLoss(\n",
    "    model=\"net-lin\", net=\"vgg\", use_gpu=device.startswith(\"cuda\")\n",
    ")\n",
    "noises_single = g_ema.make_noise()\n",
    "noises = []\n",
    "for noise in noises_single:\n",
    "    noises.append(noise.repeat(imgs.shape[0], 1, 1, 1).normal_())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_in = latent_mean.detach().clone().unsqueeze(0).repeat(imgs.shape[0], 1)\n",
    "latent_in = latent_in.unsqueeze(1).repeat(1, g_ema.n_latent, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_in.requires_grad = True\n",
    "\n",
    "for noise in noises:\n",
    "    noise.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_init = 0.01\n",
    "step = 1300\n",
    "mse = 0.1\n",
    "pn = 0.001\n",
    "\n",
    "noise_rate = 0.0\n",
    "noise_ramp = 0.75\n",
    "noise_regulr = 1e5\n",
    "\n",
    "# optimizer = optim.Adam([latent_in] + noises, lr=lr_init)\n",
    "optimizer = optim.Adam([latent_in], lr=lr_init)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "perceptual: 0.0992; noise regularize: 0.0000; mse: 0.0070; lr: 0.000000: 100%|██████████| 1300/1300 [04:43<00:00,  4.58it/s]\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(step))\n",
    "latent_path = []\n",
    "for i in pbar:\n",
    "    t = i / step\n",
    "    lr = get_lr(t, lr_init)\n",
    "    optimizer.param_groups[0][\"lr\"] = lr\n",
    "    if noise_rate > 0:\n",
    "        noise_strength = latent_std * noise_rate * max(0, 1 - t / noise_ramp) ** 2\n",
    "        latent_n = latent_noise(latent_in, noise_strength.item())\n",
    "    else:\n",
    "        latent_n = latent_in\n",
    "    img_gen, _ = g_ema([latent_n], input_is_latent=True, noise=noises)\n",
    "\n",
    "    batch, channel, height, width = img_gen.shape\n",
    "\n",
    "    if height > 256:\n",
    "        factor = height // 256\n",
    "\n",
    "        img_gen = img_gen.reshape(\n",
    "            batch, channel, height // factor, factor, width // factor, factor\n",
    "        )\n",
    "        img_gen = img_gen.mean([3, 5])\n",
    "\n",
    "    p_loss = percept(img_gen, imgs).sum()\n",
    "    \n",
    "    # n_loss = noise_regularize(noises)\n",
    "    n_loss = torch.Tensor([0]).cuda()\n",
    "\n",
    "    mse_loss = F.mse_loss(img_gen, imgs)\n",
    "\n",
    "    pn_loss = PN_loss(latent_in)\n",
    "\n",
    "    loss = p_loss + noise_regulr * n_loss + mse * mse_loss + pn * pn_loss\n",
    "\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    noise_normalize_(noises)\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        latent_path.append(latent_in.detach().clone())\n",
    "\n",
    "    pbar.set_description(\n",
    "        (\n",
    "            f\"perceptual: {p_loss.item():.4f}; noise regularize: {n_loss.item():.4f};\"\n",
    "            f\" mse: {mse_loss.item():.4f}; lr: {lr:.6f}\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "img_gen, _ = g_ema([latent_path[-1]], input_is_latent=True, noise=noises)\n",
    "\n",
    "filename = os.path.splitext(os.path.basename(imgfiles[0]))[0] + \".pt\"\n",
    "\n",
    "img_ar = make_image(img_gen)\n",
    "\n",
    "result_file = {}\n",
    "for i, input_name in enumerate(imgfiles):\n",
    "    noise_single = []\n",
    "    for noise in noises:\n",
    "        noise_single.append(noise[i : i + 1])\n",
    "\n",
    "    result_file[input_name] = {\n",
    "        \"img\": img_gen[i],\n",
    "        \"latent\": latent_in[i],\n",
    "        \"noise\": noise_single,\n",
    "    }\n",
    "\n",
    "    img_name = os.path.splitext(os.path.basename(input_name))[0] + \"-project.png\"\n",
    "    pil_img = Image.fromarray(img_ar[i])\n",
    "    pil_img.save(img_name)\n",
    "\n",
    "torch.save(result_file, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_lr(1/1000, 0.1)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cff1fbb106c8e7705f2415f761bff4697fc9c3b69c31d94528dc8102c3901e15"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
